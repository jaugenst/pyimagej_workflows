{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbdb6d-d9e3-481a-abcb-ddcdfa1b9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_overlays_to_groups(nearest, traced_ids, ij, imp):\n",
    "    \"\"\"Randomly color groups of cells.\n",
    "\n",
    "    This is Jacques' function.  It seeks to put a single-color outline\n",
    "    on each cell of a group.\n",
    "    \"\"\"\n",
    "    Overlay = scyjava.jimport('ij.gui.Overlay')\n",
    "    ov = Overlay()\n",
    "    rm = ij.RoiManager.getRoiManager()\n",
    "    rm.runCommand(\"Associated\", \"true\")\n",
    "    colors = [\"black\", \"blue\", \"cyan\", \"green\", \"magenta\",\n",
    "              \"orange\", \"red\", \"white\", \"yellow\"]\n",
    "    cell_indexes = nearest.keys()\n",
    "    cell_names = traced_ids.keys()\n",
    "    for cell in cell_names:\n",
    "        cell_idx = traced_ids[cell]\n",
    "        random_color = random.choice(colors)\n",
    "        for cell_vs_time in cell_idx:\n",
    "            chosen_index = rm.getIndex(cell_vs_time)\n",
    "            roi = rm.select(chosen_index)\n",
    "            overlay_command = f\"Overlay.addSelection('{random_color}', 5);\"\n",
    "            ij.py.run_macro(overlay_command)\n",
    "\n",
    "\n",
    "def collapse_z(raw_dataset, output_files, ij, method='sum all', wanted_channel=3,\n",
    "               show=False, verbose=False):\n",
    "    \"\"\"Drop the image down to a single Z.\n",
    "\n",
    "    Optionally, also drop to a single channel.\n",
    "    \"\"\"\n",
    "    ZProjector = scyjava.jimport('ij.plugin.ZProjector')()\n",
    "    cellpose_slices = list(output_files.keys())\n",
    "    slice_name = cellpose_slices[0]\n",
    "    slice_directory = os.path.dirname(output_files[slice_name]['input_file'])\n",
    "    base_directory = os.path.dirname(slice_directory)\n",
    "    output_directory = Path(f\"{base_directory}/collapsed\")\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    output_filename = Path(f\"{output_directory}/z_projection.tiff\").as_posix()\n",
    "    if os.path.exists(output_filename):\n",
    "        os.remove(output_filename)\n",
    "    if (wanted_channel is None):\n",
    "        imp = ij.py.to_imageplus(raw_dataset)\n",
    "    else:\n",
    "        data_info = {}\n",
    "        for element in range(len(raw_dataset.dims)):\n",
    "            name = raw_dataset.dims[element]\n",
    "            data_info[name] = raw_dataset.shape[element]\n",
    "        single_channel = raw_dataset[:, :, wanted_channel, :, :]\n",
    "        imp = ij.py.to_imageplus(single_channel)\n",
    "        imp.setDimensions(1, int(data_info['Z']), int(data_info['Time']))\n",
    "\n",
    "    z_projector_result = ZProjector.run(imp, method)\n",
    "    z_collapsed_image = ij.py.from_java(z_projector_result)\n",
    "    z_collapsed_dataset = ij.py.to_dataset(z_collapsed_image)\n",
    "    saved = ij.io().save(z_collapsed_dataset, output_filename)\n",
    "    if verbose:\n",
    "        print(f\"Saving image {output_filename}.\")\n",
    "    if show:\n",
    "        ij.ui().show(z_collapsed_dataset)\n",
    "    return z_collapsed_dataset, z_collapsed_image, output_filename, imp\n",
    "\n",
    "\n",
    "def collapse_z_separate_time(raw_dataset, output_files, ij, method='sum', verbose=True):\n",
    "    \"\"\"Stack multiple z slices for each timepoint.\n",
    "\n",
    "    If I understand Jacques' explanation of the quantification methods\n",
    "    correctly, they sometimes (often?) perform better on the\n",
    "    z-integration of pixels at each timepoint.  This function performs\n",
    "    that and sends the stacked slices to the output directory and adds\n",
    "    the filenames to the output_files dictionary.\n",
    "    \"\"\"\n",
    "    ZProjector = scyjava.jimport(\"ij.plugin.ZProjector\")()\n",
    "    cellpose_slices = list(output_files.keys())\n",
    "    slice_number = 0\n",
    "    collapsed_slices = []\n",
    "    for slice_name in cellpose_slices:\n",
    "        output_directory = os.path.dirname(output_files[slice_name]['output_txt'])\n",
    "        collapsed_directory = os.path.dirname(output_directory)\n",
    "        collapsed_directory = f\"{collapsed_directory}/collapsed\"\n",
    "        os.makedirs(collapsed_directory, exist_ok=True)\n",
    "        output_filename = Path(f\"{collapsed_directory}/frame{slice_number}.tif\").as_posix()\n",
    "        output_files[slice_name]['collapsed_file'] = output_filename\n",
    "        if os.path.exists(output_filename):\n",
    "            if verbose:\n",
    "                print(f\"Skipping {output_filename}, it already exists.\")\n",
    "        else:\n",
    "            larger_slice = raw_dataset[:, :, :, :, slice_number]\n",
    "            imp = ij.py.to_imageplus(larger_slice)\n",
    "            z_projector_result = ZProjector.run(imp, method)\n",
    "            ## z_projector_mask = ij.IJ.run(z_projector_result, \"Convert to Mask\", \"method=Otsu background=Light\")\n",
    "            z_collapsed_image = ij.py.from_java(z_projector_result)\n",
    "            z_collapsed_dataset = ij.py.to_dataset(z_collapsed_image)\n",
    "            saved = ij.io().save(z_collapsed_dataset, output_filename)\n",
    "            if verbose:\n",
    "                print(f\"Saving image {output_filename}.\")\n",
    "        slice_number = slice_number + 1\n",
    "    return output_files\n",
    "\n",
    "\n",
    "def convert_slices_to_pandas(slices, verbose=False):\n",
    "    \"\"\"Dump the cellpose_result slice data to a single df.\n",
    "\n",
    "    There is no good reason for me to store the data as a series of\n",
    "    dataframes within a dictionary except I want to get more\n",
    "    comfortable with python datastructures.  Thus, this function\n",
    "    should be extraneous, but serves as a way to go from my hash to a\n",
    "    single df.\n",
    "    \"\"\"\n",
    "    concatenated = pandas.DataFrame()\n",
    "    slice_keys = list(slices.keys())\n",
    "    slice_counter = 0\n",
    "    for k in slice_keys:\n",
    "        slice_counter = slice_counter + 1\n",
    "        current_slice = slices[k]\n",
    "        if verbose:\n",
    "            print(f\"The slice is {k}\")\n",
    "        slice_number = current_slice['slice_number']\n",
    "        slice_data = current_slice['measurements']\n",
    "        slice_data['Frame'] = slice_number\n",
    "        if slice_counter == 1:\n",
    "            concatenated = slice_data\n",
    "        else:\n",
    "            concatenated = pandas.concat([concatenated, slice_data])\n",
    "    ## This is a little silly, but I couldn't remember that the index attribute\n",
    "    ## is the numeric rowname for a moment\n",
    "    ## The reset_index() does what it says on the tine, and changes the 1:19, 1:20, etc\n",
    "    ## of each individual time Frame to a single range of 1:2000\n",
    "    concatenated.index = concatenated.reset_index().index\n",
    "    return concatenated\n",
    "\n",
    "\n",
    "def create_cellpose_rois(output_files, ij, raw_image, imp, collapsed=False, verbose=True,\n",
    "                         delete=False, max_frames=3):\n",
    "    \"\"\"Read the text cellpose output files, generate ROIs.\"\"\"\n",
    "    cellpose_slices = list(output_files.keys())\n",
    "    data_info = {}\n",
    "    for element in range(len(raw_image.dims)):\n",
    "        name = raw_image.dims[element]\n",
    "        data_info[name] = raw_image.shape[element]\n",
    "    num_times = data_info['Time'] + 1\n",
    "    num_channels = data_info['Channel']\n",
    "    num_z = data_info['Z']\n",
    "\n",
    "    Overlay = scyjava.jimport('ij.gui.Overlay')\n",
    "    ov = Overlay()\n",
    "    rm = ij.RoiManager.getRoiManager()\n",
    "    rm.runCommand(\"Associated\", \"true\")\n",
    "    slice_directory = ''\n",
    "    print(\"Starting to iterate over times.\")\n",
    "    for timepoint in range(1, num_times):\n",
    "        frame_number = timepoint - 1 ## I used 0-indexed for the frames.\n",
    "        print(f\"Going to time: {timepoint}\")\n",
    "        imp.setT(timepoint)\n",
    "        slice_name = f\"frame_{frame_number}\"\n",
    "        input_tif = output_files[slice_name]['input_file']\n",
    "        slice_directory_name = os.path.basename(os.path.dirname(os.path.dirname(input_tif)))\n",
    "        input_txt = output_files[slice_name]['output_txt']\n",
    "        input_mask = output_files[slice_name]['output_mask']\n",
    "        ## The logic for this was taken from:\n",
    "        ## https://stackoverflow.com/questions/73849418/is-there-any-way-to-switch-imagej-macro-code-to-python3-code\n",
    "        txt_fh = open(input_txt, 'r')\n",
    "        roi_stats = defaultdict(list)\n",
    "        frame_xcoords = []\n",
    "        frame_ycoords = []\n",
    "        coords_length = []\n",
    "        ## Now get the slice for this timepoint from the raw data\n",
    "        for line in txt_fh:\n",
    "            xy = line.rstrip().split(\",\")\n",
    "            xy_coords = [int(element) for element in xy if element not in '']\n",
    "            x_coords = [int(element) for element in xy[::2] if element not in '']\n",
    "            y_coords = [int(element) for element in xy[1::2] if element not in '']\n",
    "            xcoords_jint = JArray(JInt)(x_coords)\n",
    "            ycoords_jint = JArray(JInt)(y_coords)\n",
    "            polygon_roi_instance = scyjava.jimport('ij.gui.PolygonRoi')\n",
    "            roi_instance = scyjava.jimport('ij.gui.Roi')\n",
    "            imported_polygon = polygon_roi_instance(xcoords_jint, ycoords_jint,\n",
    "                                                    len(x_coords), int(roi_instance.POLYGON))\n",
    "            imp.setRoi(imported_polygon)\n",
    "            added = rm.addRoi(imported_polygon)\n",
    "            roi_count = rm.getCount() ## Get the current number of ROIs, 1 indexed.\n",
    "            roi_zero_idx = roi_count - 1\n",
    "            selected = rm.select(roi_zero_idx)\n",
    "            time_set = imp.setT(timepoint)\n",
    "            updated = rm.runCommand(\"Update\")\n",
    "            print(f\"Finished time: {timepoint} ROI: {roi_count}\")\n",
    "        txt_fh.close()\n",
    "    imp.show()\n",
    "    roi_index = JArray(JInt)(range(0, rm.getCount()))\n",
    "    rm.setSelectedIndexes(roi_index)\n",
    "    ## Note to self, add a variant of this save to the measure function.\n",
    "    rm.runCommand('Save', f\"{slice_directory_name}.zip\")\n",
    "    if delete:\n",
    "        rm.runCommand('Delete')\n",
    "    return output_files\n",
    "\n",
    "\n",
    "# Relevant options:\n",
    "# batch_size(increase for more parallelization), channels(two element list of two element\n",
    "# channels to segment; the first is the segment, second is optional nucleus;\n",
    "# internal elements are color channels to query, so [[0,0],[2,3]] means do main cells in\n",
    "# grayscale and a second with cells in blue, nuclei in green.\n",
    "# channel_axis, z_axis ? invert (T/F flip pixels from b/w I assume),\n",
    "# normalize(T/F percentile normalize the data), diameter, do_3d,\n",
    "# anisotropy (rescaling factor for 3d segmentation), net_avg (average models),\n",
    "# augment ?, tile ?, resample, interp, flow_threshold, cellprob_threshold (interesting),\n",
    "# min_size (turned off with -1), stitch_threshold ?, rescale ?.\n",
    "def invoke_cellpose(input_directory, model_file, channels=[[0, 0]], diameter=160,\n",
    "                    threshold=0.4, do_3D=False, batch_size=64, verbose=True, gpu=False):\n",
    "    \"\"\"Invoke cellpose using individual slices.\n",
    "\n",
    "    This takes the series of slices from separate_slices() and sends\n",
    "    them to cellpose with a specific model.  The dictionary it returns\n",
    "    is the primary datastructure for the various functions which follow.\n",
    "    \"\"\"\n",
    "\n",
    "    # Relevant options:\n",
    "    # model_type(cyto, nuclei, cyto2), net_avg(T/F if load built in networks and average them)\n",
    "    model = models.CellposeModel(gpu=gpu, pretrained_model=model_file)\n",
    "    slice_directory = Path(f\"{input_directory}/slices\").as_posix()\n",
    "    files = get_image_files(slice_directory, '_masks', look_one_level_down=False)\n",
    "    needed_imgs = []\n",
    "    output_masks = []\n",
    "    output_txts = []\n",
    "    output_files = defaultdict(dict)\n",
    "    existing_files = 0\n",
    "    count = 0\n",
    "    for one_file in files:\n",
    "        print(f\"Reading {one_file}\")\n",
    "        cp_output_directory = Path(f\"{input_directory}/cellpose\").as_posix()\n",
    "        os.makedirs(cp_output_directory, exist_ok=True)\n",
    "        f_name = os.path.basename(one_file)\n",
    "        f_name = os.path.splitext(f_name)[0]\n",
    "        start_mask = Path(f\"{slice_directory}/{f_name}_cp_masks.png\").as_posix()\n",
    "        output_mask = Path(f\"{cp_output_directory}/{f_name}_cp_masks.png\").as_posix()\n",
    "        start_txt = Path(f\"{slice_directory}/{f_name}_cp_outlines.txt\").as_posix()\n",
    "        output_txt = Path(f\"{cp_output_directory}/{f_name}_cp_outlines.txt\").as_posix()\n",
    "        print(f\"Adding new txt file: {output_txt}\")\n",
    "        output_files[f_name]['input_file'] = one_file\n",
    "        output_files[f_name]['start_mask'] = start_mask\n",
    "        output_files[f_name]['output_mask'] = output_mask\n",
    "        output_files[f_name]['start_txt'] = start_txt\n",
    "        output_files[f_name]['output_txt'] = output_txt\n",
    "        output_files[f_name]['exists'] = False\n",
    "        if (os.path.exists(start_txt) or os.path.exists(output_txt)):\n",
    "            existing_files = existing_files + 1\n",
    "            print(f\"This file already exists: {start_txt}\")\n",
    "            output_files[f_name]['exists'] = True\n",
    "        else:\n",
    "            print(f\"This file does not exist: {start_txt}\")\n",
    "            img = imread(one_file)\n",
    "            needed_imgs.append(img)\n",
    "        count = count + 1\n",
    "    nimg = len(needed_imgs)\n",
    "    if verbose and nimg > 0:\n",
    "        print(f\"Reading {nimg} images, starting cellpose.\")\n",
    "        masks, flows, styles = model.eval(needed_imgs, diameter=diameter,\n",
    "                                          channels=channels, flow_threshold=threshold,\n",
    "                                          do_3D=do_3D, batch_size=batch_size)\n",
    "        saved = io.save_to_png(needed_imgs, masks, flows, files)\n",
    "    else:\n",
    "        print(\"Returning the output files.\")\n",
    "    return output_files\n",
    "\n",
    "\n",
    "def move_cellpose_output(output_files, verbose=False):\n",
    "    \"\"\"Cellpose puts its output files into the cwd, I want them in specific directories.\"\"\"\n",
    "    print(f\"Moving cellpose outputs to the cellpose output directory.\")\n",
    "    output_filenames = list(output_files.keys())\n",
    "    for f_name in output_filenames:\n",
    "        output_file = output_files[f_name]['output_mask']\n",
    "        if (os.path.exists(output_file)):\n",
    "            if verbose:\n",
    "                print(\"The output already exists.\")\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"Moving {output_files[f_name]['start_mask']} to {output_file}\")\n",
    "            mask_moved = shutil.move(output_files[f_name]['start_mask'],\n",
    "                                     output_files[f_name]['output_mask'])\n",
    "            txt_moved = shutil.move(output_files[f_name]['start_txt'],\n",
    "                                    output_files[f_name]['output_txt'])\n",
    "\n",
    "\n",
    "def nearest_cells_over_time(df, max_dist=200.0, max_prop=None, x_column='X',\n",
    "                            y_column='Y', verbose=True):\n",
    "    \"\"\"Trace cells over time\n",
    "\n",
    "    If I understand Jacques' goals correctly, the tracing of cells\n",
    "    over time should be a reasonably tractable problem for the various\n",
    "    geo-statistics tools to handle; their whole purpose is to\n",
    "    calculate n-dimensional distances.  So, let us pass my df to one\n",
    "    of them and see what happens!\n",
    "\n",
    "    Upon completion, we should get an array(dictionary? I forget) of\n",
    "    arrays where each primary key is the top-level cell ID.  Each\n",
    "    internal array is the set of IDs from the geopandas dataframe,\n",
    "    which contains all of the measurements.  Thus, we can easily\n",
    "    extract the data for individual cells and play with it.\n",
    "    \"\"\"\n",
    "    gdf = geopandas.GeoDataFrame(\n",
    "        df, geometry=geopandas.points_from_xy(df[x_column], df[y_column]))\n",
    "    final_time = gdf.Frame.max()\n",
    "    pairwise_distances = []\n",
    "    for start_time in range(0, final_time):\n",
    "        i = start_time\n",
    "        j = i + 1\n",
    "        ti_idx = gdf.Frame == i\n",
    "        tj_idx = gdf.Frame == j\n",
    "        if verbose:\n",
    "            print(f\"Getting distances of dfs {i} and {j}.\")\n",
    "        ti = gdf[ti_idx]\n",
    "        tj = gdf[tj_idx]\n",
    "        ti_rows = ti.shape[0]\n",
    "        tj_rows = tj.shape[0]\n",
    "        for ti_row in range(0, ti_rows):\n",
    "            ti_element = ti.iloc[[ti_row, ]]\n",
    "            titj = geopandas.sjoin_nearest(ti_element, tj, distance_col=\"pairwise_dist\",\n",
    "                                           max_distance=max_dist)\n",
    "            chosen_closest_dist = titj.pairwise_dist.min()\n",
    "            if (isnan(chosen_closest_dist)):\n",
    "                print(f\"This element has no neighbor within {max_dist}.\")\n",
    "            else:\n",
    "                chosen_closest_cell = titj.pairwise_dist == chosen_closest_dist\n",
    "                chosen_closest_row = titj[chosen_closest_cell]\n",
    "                pairwise_distances.append(chosen_closest_row)\n",
    "\n",
    "    paired = pandas.concat(pairwise_distances)\n",
    "    id_counter = 0\n",
    "    ## Cell IDs pointing to a list of cells\n",
    "    traced = {}\n",
    "    ## Endpoints pointing to the cell IDs\n",
    "    ends = {}\n",
    "\n",
    "    traced_ids = {}\n",
    "    cellids_to_startid = {}\n",
    "    for i in range(0, final_time):\n",
    "        query_idx = paired.Frame_left == i\n",
    "        query = paired[query_idx]\n",
    "        for row in query.itertuples():\n",
    "            start_cell = row.Index\n",
    "            start_cellid = row.cell_id_left\n",
    "            end_cell = row.index_right\n",
    "            end_cellid = row.cell_id_right\n",
    "\n",
    "            ## If the current cell ID maps to a starting point, then\n",
    "            ## add the new endpoint to the traced_ids with that starting cell.\n",
    "            ## Then add another key to cellids_to_startid with the new endpoint.\n",
    "            if start_cellid in cellids_to_startid:\n",
    "                parent = cellids_to_startid[start_cellid]\n",
    "                current_id_list = traced_ids[parent]\n",
    "                current_id_list.append(end_cellid)\n",
    "                traced_ids[parent] = current_id_list\n",
    "                cellids_to_startid[end_cellid] = parent\n",
    "            else:\n",
    "                ## If there is no current ID mapping, create one.\n",
    "                parent = start_cellid\n",
    "                cellids_to_startid[end_cellid] = parent\n",
    "                cellids_to_startid[parent] = parent\n",
    "                traced_ids[parent] = [parent, end_cellid]\n",
    "\n",
    "            if start_cell in ends.keys():\n",
    "                cell_id = ends[start_cell]\n",
    "                current_value = traced[cell_id]\n",
    "                current_value.append(end_cell)\n",
    "                traced[cell_id] = current_value\n",
    "                ends[end_cell] = cell_id\n",
    "            else:\n",
    "                id_counter = id_counter + 1\n",
    "                traced[id_counter] = [start_cell, end_cell]\n",
    "                ends[end_cell] = id_counter\n",
    "    return traced, traced_ids, paired, pairwise_distances\n",
    "\n",
    "\n",
    "def separate_slices(input_file, ij, raw_image=None,\n",
    "                    wanted_x=True, wanted_y=True, wanted_z=1,\n",
    "                    wanted_channel=2, cpus=8, overwrite=False, verbose=True):\n",
    "    \"\"\"Slice an image in preparation for cellpose.\n",
    "\n",
    "    Eventually this should be smart enough to handle arbitrary\n",
    "    x,y,z,channels,times as well as able to use multiple cpus for\n",
    "    saving the data.  In its current implementation, it only saves 1\n",
    "    z, 1 channel for every frame of an image into a series of files in\n",
    "    its output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    input_base = os.path.basename(input_file)\n",
    "    input_dir = os.path.dirname(input_file)\n",
    "    input_name = os.path.splitext(input_base)[0]\n",
    "    output_directory = Path(f\"{input_dir}/outputs/{input_name}_z{wanted_z}\").as_posix()\n",
    "    slice_directory = Path(f\"{output_directory}/slices\").as_posix()\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    os.makedirs(slice_directory, exist_ok=True)\n",
    "    if (raw_image is None):\n",
    "        print(\"Starting to open the input file, this takes a moment.\")\n",
    "        raw_image = ij.io().open(input_file)\n",
    "    if verbose:\n",
    "        print(f\"Opened input file, writing images to {output_directory}\")\n",
    "\n",
    "    data_info = {}\n",
    "    for element in range(len(raw_image.dims)):\n",
    "        name = raw_image.dims[element]\n",
    "        data_info[name] = raw_image.shape[element]\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"This dataset has dimensions: X:{data_info['X']}\",\n",
    "            f\"Y:{data_info['Y']} Z:{data_info['Z']} Time:{data_info['Time']}\",\n",
    "        )\n",
    "\n",
    "    slices = []\n",
    "    for timepoint in range(data_info['Time']):\n",
    "        wanted_slice = raw_image[:, :, wanted_channel, wanted_z, timepoint]\n",
    "        slice_data = ij.py.to_dataset(wanted_slice)\n",
    "        output_filename = Path(f\"{output_directory}/slices/frame_{timepoint}.tif\").as_posix()\n",
    "        if os.path.exists(output_filename):\n",
    "            if overwrite:\n",
    "                print(f\"Rewriting {output_filename}\")\n",
    "                os.remove(output_filename)\n",
    "                saved = ij.io().save(slice_data, output_filename)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"Skipping {output_filename}, it already exists.\")\n",
    "        else:\n",
    "            saved = ij.io().save(slice_data, output_filename)\n",
    "            if verbose:\n",
    "                print(f\"Saving image {input_name}_{timepoint}.\")\n",
    "        slices.append(wanted_slice)\n",
    "    print(f\"Returning the output directory: {output_directory}\")\n",
    "    return raw_image, slices, output_directory\n",
    "\n",
    "\n",
    "## The following is from a mix of a couple of implementations I found:\n",
    "## https://pyimagej.readthedocs.io/en/latest/Classic-Segmentation.html\n",
    "## an alternative method may be taken from:\n",
    "## https://pyimagej.readthedocs.io/en/latest/Classic-Segmentation.html#segmentation-workflow-with-imagej2\n",
    "## My goal is to pass the ROI regions to this function and create a similar df.\n",
    "def slices_to_roi_measurements(cellpose_result, ij, imp,\n",
    "                               collapsed=False, verbose=True, view_channel=4,\n",
    "                               view_z=10):\n",
    "    \"\"\"Read the text cellpose output files, generate ROIs, and measure.\n",
    "\n",
    "    I think there are better ways of accomplishing this task than\n",
    "    using ij.IJ.run(); but this seems to work...  Upon completion,\n",
    "    this function should add a series of dataframes to the\n",
    "    cellpose_result dictionary which comprise the various metrics from\n",
    "    ImageJ's measurement function of the ROIs detected by cellpose.\n",
    "    \"\"\"\n",
    "\n",
    "    showPolygonRoi = scyjava.jimport('ij.gui.PolygonRoi')\n",
    "    Overlay = scyjava.jimport('ij.gui.Overlay')\n",
    "    Regions = scyjava.jimport('net.imglib2.roi.Regions')\n",
    "    LabelRegions = scyjava.jimport('net.imglib2.roi.labeling.LabelRegions')\n",
    "    ZProjector = scyjava.jimport('ij.plugin.ZProjector')()\n",
    "    ov = Overlay()\n",
    "    rm = ij.RoiManager.getRoiManager()\n",
    "    rm.runCommand(\"Associated\", \"true\")\n",
    "    dimensions = imp.getDimensions()\n",
    "    channels = ij.py.from_java(dimensions)[2]\n",
    "    if (channels > 1):\n",
    "        imp.resetDisplayRanges()\n",
    "    else:\n",
    "        imp.resetDisplayRange()\n",
    "\n",
    "    ij.py.run_macro('resetMinAndMax();')\n",
    "    output_dict = cellpose_result\n",
    "    cellpose_slices = list(cellpose_result.keys())\n",
    "    slice_number = 0\n",
    "    roi_index = 0\n",
    "    for slice_name in cellpose_slices:\n",
    "        output_dict[slice_name]['slice_number'] = slice_number\n",
    "        ## I am not sure if time is 0 or 1 indexed.\n",
    "        timepoint = slice_number + 1\n",
    "        print(f\"Looking at slice: {slice_number} which is time: {timepoint}\")\n",
    "        imp.setT(timepoint)\n",
    "        if (view_channel):\n",
    "            imp.setC(view_channel)\n",
    "        if (view_z):\n",
    "            imp.setZ(view_z)\n",
    "        input_tif = ''\n",
    "        input_txt = cellpose_result[slice_name]['output_txt']\n",
    "        input_mask = cellpose_result[slice_name]['output_mask']\n",
    "        if verbose:\n",
    "            print(f\"Processing cellpose outline: {input_txt}\")\n",
    "            print(f\"Measuring: {input_tif}\")\n",
    "        ## Set up the measurement parameters\n",
    "        set_string = f'Set Measurements...'\n",
    "        measure_string = f'area mean min centroid median skewness kurtosis integrated stack redirect=None decimal=3'\n",
    "        measure_setup = ij.IJ.run(set_string, measure_string)\n",
    "        txt_fh = open(input_txt, 'r')\n",
    "        roi_stats = defaultdict(list)\n",
    "        slice_element = 0\n",
    "        slice_roi_names = []\n",
    "        for line in txt_fh:\n",
    "            xy = line.rstrip().split(\",\")\n",
    "            xy_coords = [int(element) for element in xy if element not in '']\n",
    "            x_coords = [int(element) for element in xy[::2] if element not in '']\n",
    "            y_coords = [int(element) for element in xy[1::2] if element not in '']\n",
    "            xcoords_jint = JArray(JInt)(x_coords)\n",
    "            ycoords_jint = JArray(JInt)(y_coords)\n",
    "            polygon_roi_instance = scyjava.jimport('ij.gui.PolygonRoi')\n",
    "            roi_instance = scyjava.jimport('ij.gui.Roi')\n",
    "            imported_polygon = polygon_roi_instance(\n",
    "                xcoords_jint, ycoords_jint, len(x_coords), int(roi_instance.POLYGON)\n",
    "            )\n",
    "            roi_name = f\"t{slice_number}_c{slice_element}\"\n",
    "            slice_roi_names.append(roi_name)\n",
    "            imp.setRoi(imported_polygon)\n",
    "            added = rm.addRoi(imported_polygon)\n",
    "            current_index = rm.getCount() - 1\n",
    "            current_name = rm.getName(current_index)\n",
    "            renamed = rm.rename(current_index, roi_name)\n",
    "            selected = rm.select(current_index)\n",
    "            imp.setT(timepoint)\n",
    "            if (view_channel):\n",
    "                imp.setC(view_channel)\n",
    "            #if (view_z):\n",
    "            #    imp.setZ(view_z)\n",
    "            rm.runCommand(\"Update\")\n",
    "            slice_element = slice_element + 1\n",
    "            roi_index = roi_index + 1\n",
    "            measured = ij.IJ.run(imp, 'Measure', '')\n",
    "            ## All ROIs for this frame have been measured, send the results back to a dataframe\n",
    "        txt_fh.close()\n",
    "        slice_result = ij.ResultsTable.getResultsTable()\n",
    "        slice_table = ij.convert().convert(\n",
    "            slice_result, scyjava.jimport('org.scijava.table.Table')\n",
    "        )\n",
    "        slice_measurements = ij.py.from_java(slice_table)\n",
    "        slice_measurements['cell_id'] = slice_roi_names\n",
    "        output_dict[slice_name]['measurements'] = slice_measurements\n",
    "        ij.IJ.run('Clear Results')\n",
    "        imp.show()\n",
    "        imp.setOverlay(ov)\n",
    "        slice_number = slice_number + 1\n",
    "        ## All frames have been measured\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def start_fiji(base=None, mem='-Xmx128g', location='venv/bin/Fiji.app',\n",
    "               mode='interactive', input_file=None):\n",
    "    \"\"\"Start fiji with some default options and return the data structures of interest.\n",
    "\n",
    "    Depending on context, one might want access to a few different things provided\n",
    "    by fiji/pyimagej when starting up.  This function attempts to make the process\n",
    "    of starting the fiji instance and grabbing the ij, raw image data, and imageplus\n",
    "    data as easy as possible.\n",
    "    \"\"\"\n",
    "    scyjava.config.add_option(mem)\n",
    "    start_dir = os.getcwd()\n",
    "    if base:\n",
    "        start_dir = base\n",
    "    ij = imagej.init(Path(location), mode=mode)\n",
    "    ij.getApp().getInfo(True)\n",
    "    ij.ui().showUI()\n",
    "    ## Something about this init() function changes the current working directory.\n",
    "    os.chdir(start_dir)\n",
    "    ij.getVersion()\n",
    "    raw_image = None\n",
    "    imp = None\n",
    "    if input_file:\n",
    "        raw_image = ij.io().open(input_file)\n",
    "        shown = ij.ui().show(raw_image)\n",
    "        imp = ij.py.to_imageplus(raw_image)\n",
    "        imp.show()\n",
    "    return ij, raw_image, imp\n",
    "\n",
    "\n",
    "def write_cell_measurements(traced_ids, paired,\n",
    "                            output='cell_measurements.csv'):\n",
    "    \"\"\"Write cell-by-cell measurements to a csv file.\n",
    "\n",
    "    This uses the to_csv() function provided by pandas to write out the various metrics\n",
    "    produced by imageJ to a file in cell ID order.  The parental ID is first, followed by\n",
    "    the current cell, the next cell, then all other metrics.\n",
    "    \"\"\"\n",
    "    cell_num = 0\n",
    "    for parent_cellid in traced_ids:\n",
    "        cell_group = traced_ids[parent_cellid]\n",
    "        for child_cell in cell_group:\n",
    "            data_idx = paired.cell_id_left == child_cell\n",
    "            new_row = paired[data_idx]\n",
    "            ## Move the parent, left, and right cell IDs to the beginning of the row.\n",
    "            new_row.insert(0, 'parent_cell', parent_cellid)\n",
    "            left_popped = new_row.pop('cell_id_left')\n",
    "            new_row.insert(1, 'cell_id_left', left_popped)\n",
    "            right_popped = new_row.pop('cell_id_right')\n",
    "            new_row.insert(2, 'cell_id_right', right_popped)\n",
    "            num_hits = sum(data_idx)\n",
    "            if (num_hits > 0):\n",
    "                cell_num = cell_num + 1\n",
    "                if (cell_num == 1):\n",
    "                    new_row.to_csv(output, mode='w', header=True)\n",
    "                else:\n",
    "                    new_row.to_csv(output, mode='a', header=False)\n",
    "    return cell_num\n",
    "\n",
    "\n",
    "def write_nearest_cellids(nearest, output='nearest.csv'):\n",
    "    \"\"\"Write a csv file of cell IDs.\n",
    "\n",
    "    This uses the csv library to write out the cell IDs, one per line.\n",
    "    \"\"\"\n",
    "    with open(output, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        field_names = ['parent_cell_id', 'child_cell_ids']\n",
    "        writer.writerow(field_names)\n",
    "        for near in nearest.keys():\n",
    "            value = nearest[near]\n",
    "            ## cleaned = value.strip(']').strip(']')\n",
    "            writer.writerow([near, value])\n",
    "    print(f\"Wrote numeric cell IDs to the file: {output}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb4064-2c8c-41e0-9008-04e4f4cf0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dir = os.getcwd()\n",
    "mem = '-Xmx30g'\n",
    "location = '/home/saka/sw/local/fiji/2023'\n",
    "mode = 'interactive'\n",
    "\n",
    "ij, raw_image, imp = start_fiji(base=start_dir, mem=mem, location=location, mode=mode,\n",
    "                                input_file=input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa3556-e470-435f-bbe0-29a03cf4e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset, saved_slices, output_directory = separate_slices(input_file, ij, raw_image = raw_image, wanted_z = 2,\n",
    "                                                              wanted_channel = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e9e28-3af6-4532-bc32-1ad955e4ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = invoke_cellpose(output_directory, '/home/saka/Documents/CP_20220523_104016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74fa91-76f4-471f-8665-fd1b41da9bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_cellpose_output(output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881206a-a115-41d6-99ba-2e182ab5091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_collapsed, z_collapsed_image, output_file, imp = collapse_z(raw_dataset, output_files, ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7068f-9978-4da5-a8be-305db32e7177",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = ij.py.to_imageplus(z_collapsed)\n",
    "## I think I would like to have this function be smart enough to know\n",
    "## If the input is an imageplus or raw image and convert without intervention.\n",
    "slice_measurements = slices_to_roi_measurements(output_files, ij, imp,\n",
    "                                                view_channel=4, view_z=None, collapsed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbe986-a455-4f97-9746-08579fed0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = convert_slices_to_pandas(slice_measurements)\n",
    "concatenated.shape[0]\n",
    "concatenated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f79fc-3fc0-4b80-bed1-b5c9e87df760",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest, traced_ids, paired, pairwise_distances = nearest_cells_over_time(\n",
    "    concatenated, max_dist = 101.0, x_column = 'X', y_column = 'Y')\n",
    "#for t in traced_ids:\n",
    "#    print(f\"{t}: {traced_ids[t]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5edf5b-bb60-4fcc-bc24-37a341088934",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_overlays_to_groups(nearest, traced_ids, ij, imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a88fe-339c-4715-b988-72dd788c6633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "written = write_nearest_cellids(nearest, output='nearest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8970d2-79a7-4924-8ee2-7fe8ee4b23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = 291\n",
    "cell_idx = nearest[cell_id]\n",
    "cell_data = concatenated.loc[cell_idx]\n",
    "len(cell_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b118d35-d3da-4e6c-8cf8-82d4b431462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data = cell_data.reset_index()\n",
    "\n",
    "scatter = plt.scatter(cell_data['X'], cell_data['Y'])\n",
    "final_row = cell_data.index.max()\n",
    "for start_time in range(0, final_row - 1):\n",
    "    ti_idx = cell_data.index == start_time\n",
    "    tj_idx = cell_data.index == start_time + 1\n",
    "    p1x = cell_data[ti_idx].X\n",
    "    p2x = cell_data[tj_idx].X\n",
    "    p1y = cell_data[ti_idx].Y\n",
    "    p2y = cell_data[tj_idx].Y\n",
    "    x_points = [p1x, p2x]\n",
    "    y_points = [p1y, p2y]\n",
    "    plt.plot(x_points, y_points)\n",
    "finalm1_idx = cell_data.index == final_row - 1\n",
    "final_idx = cell_data.index == final_row\n",
    "finalm1_x = cell_data[finalm1_idx].X\n",
    "final_x = cell_data[final_idx].X\n",
    "finalm1_y = cell_data[finalm1_idx].Y\n",
    "final_y = cell_data[final_idx].Y\n",
    "x_points = [finalm1_x, final_x]\n",
    "y_points = [finalm1_y, final_y]\n",
    "plt.plot(x_points, y_points)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e13a36-4fb6-4a7a-bf5e-22af6cf4f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.violinplot(data = cell_data.Area)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c3fa9-0219-494f-898b-e481b2dea1e3",
   "metadata": {},
   "source": [
    "### overlay for nearest datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d25052-83df-48bf-a771-ff48d6b0189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "colors = [\"black\", \"blue\", \"cyan\", \"green\", \"magenta\", \"orange\", \"red\", \"white\", \"yellow\"]\n",
    "\n",
    "cell_id = nearest.keys()\n",
    "for i in cell_id :\n",
    "    cell_idx = nearest[i]\n",
    "    random_color = random.choice(colors)\n",
    "    #cell_data = concatenated.loc[cell_idx]\n",
    "# Iterate over the cell_idx values\n",
    "    for idx in cell_idx:\n",
    "        # Get the ROI from the ROI Manager \n",
    "        roi = rm.select(idx)\n",
    "        overlay_command = f\"Overlay.addSelection('{random_color}', 5);\"\n",
    "        # Add the ROI to the array\n",
    "        ij.py.run_macro(overlay_command)ack\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dfcb19-dbed-40dd-a48d-61a9f215da2b",
   "metadata": {},
   "source": [
    "if you just want a specific one being overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a8f8e-b8a8-4714-b383-34f65604dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in prout:\n",
    "    roi = rm.select(idx)\n",
    "    overlay_command = f\"Overlay.addSelection('Blue',20);\"\n",
    "    ij.py.run_macro(overlay_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e8519-a78b-4e87-bdc5-e7e3ea666392",
   "metadata": {},
   "source": [
    "### Overlay from the nearest.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef1a95-966e-4a45-90b1-5f89e2882b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "colors = [\"black\", \"blue\", \"cyan\", \"green\", \"magenta\", \"orange\", \"red\", \"white\", \"yellow\"]\n",
    "\n",
    "for i in range (len(testing)):\n",
    "    single_row = testing.iloc[i]\n",
    "    row_cellids = single_row.child_cell_ids\n",
    "    row_cleaned = row_cellids.strip('[').strip(']')\n",
    "    row_array = row_cleaned.split(', ')\n",
    "    random_color = random.choice(colors)\n",
    "    for cell in row_array:\n",
    "        print(f\"This row has cell: {cell}\")\n",
    "        cell_index = int(cell)\n",
    "        roi = rm.select(cell_index)\n",
    "        overlay_command = f\"Overlay.addSelection('{random_color}', 5);\"\n",
    "        ij.py.run_macro(overlay_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d316acf-00c4-473c-9b8c-ed8fb13f03fc",
   "metadata": {},
   "source": [
    "### Overlay just selected cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f5f4c-e480-4747-96a3-7d8ccc1f04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to just double check the cells I selected\n",
    "import random\n",
    "colors = [\"black\", \"blue\", \"cyan\", \"green\", \"magenta\", \"orange\", \"red\", \"white\", \"yellow\"]\n",
    "cells = [17,10,9,3,26,7,21,46,44,23,47,29,36]\n",
    "for i in cells:\n",
    "    single_row = testing.iloc[i]\n",
    "    row_cellids = single_row.child_cell_ids\n",
    "    row_cleaned = row_cellids.strip('[').strip(']')\n",
    "    row_array = row_cleaned.split(', ')\n",
    "    random_color = random.choice(colors)\n",
    "    for cell in row_array:\n",
    "        print(f\"This row has cell: {cell}\")\n",
    "        cell_index = int(cell)\n",
    "        roi = rm.select(cell_index)\n",
    "        overlay_command = f\"Overlay.addSelection('{random_color}', 5);\"\n",
    "        ij.py.run_macro(overlay_command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
