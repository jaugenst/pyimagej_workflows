{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ae77b-6b34-4af8-9c98-264e0471536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagej \n",
    "\n",
    "#state where your fiji.app is located to access plugins and extensions\n",
    "\n",
    "ij_path = 'D:/Fiji.app'\n",
    "ij = imagej.init(ij_path, mode='interactive', add_legacy=True) \n",
    "\n",
    "print(ij.getVersion())\n",
    "\n",
    "import scyjava as sj\n",
    "import pandas as pd\n",
    "import sys, glob\n",
    "import os\n",
    "import csv\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import glob\n",
    "#from natsort import index_natsorted\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "gui = sj.jimport('ij.gui.YesNoCancelDialog')\n",
    "Frame = sj.jimport('java.awt.Frame') \n",
    "File = sj.jimport('java.io.File') \n",
    "Color= sj.jimport('java.awt.Color') \n",
    "\n",
    "\n",
    "IJ = sj.jimport('ij.IJ')\n",
    "ImageJ= sj.jimport('ij.ImageJ')\n",
    "Imagestack= sj.jimport('ij.ImageStack')\n",
    "w = sj.jimport('ij.WindowManager')\n",
    " \n",
    "ImageCalculator = sj.jimport('ij.plugin.ImageCalculator')\n",
    "FolderOpener = sj.jimport('ij.plugin.FolderOpener')\n",
    "ZProjector = sj.jimport('ij.plugin.ZProjector')\n",
    " \n",
    "Model =  sj.jimport('fiji.plugin.trackmate.Model')\n",
    "Settings= sj.jimport('fiji.plugin.trackmate.Settings')\n",
    "TrackMate = sj.jimport('fiji.plugin.trackmate.TrackMate')\n",
    "Logger= sj.jimport('fiji.plugin.trackmate.Logger')\n",
    "DetectorKeys= sj.jimport('fiji.plugin.trackmate.detection.DetectorKeys') \n",
    "ExportTracksToXML= sj.jimport('fiji.plugin.trackmate.action.ExportTracksToXML') \n",
    "TmXmlWriter= sj.jimport('fiji.plugin.trackmate.io.TmXmlWriter')\n",
    "LogRecorder = sj.jimport('fiji.plugin.trackmate.util.LogRecorder')\n",
    "SparseLAPTrackerFactory= sj.jimport('fiji.plugin.trackmate.tracking.jaqaman.SparseLAPTrackerFactory')\n",
    "TMUtils = sj.jimport('fiji.plugin.trackmate.util.TMUtils')\n",
    "HyperStackDisplayer = sj.jimport('fiji.plugin.trackmate.visualization.hyperstack.HyperStackDisplayer')\n",
    "SelectionModel = sj.jimport('fiji.plugin.trackmate.SelectionModel')\n",
    "CellposeDetectorFactory = sj.jimport('fiji.plugin.trackmate.cellpose.CellposeDetectorFactory')\n",
    "FeatureFilter = sj.jimport('fiji.plugin.trackmate.features.FeatureFilter')\n",
    "DisplaySetting = sj.jimport('fiji.plugin.trackmate.gui.displaysettings.DisplaySettings')\n",
    "DisplaySettingsIO = sj.jimport('fiji.plugin.trackmate.gui.displaysettings.DisplaySettingsIO')\n",
    "CaptureOverlayAction = sj.jimport('fiji.plugin.trackmate.action.CaptureOverlayAction')\n",
    "PretrainedModel= sj.jimport('fiji.plugin.trackmate.cellpose.CellposeSettings.PretrainedModel')\n",
    "\n",
    "\n",
    "\n",
    "class image_processor():\n",
    "    #image_directory accepts a path item with either nontransformed images (stack_reg=True) or transformed images(False)\n",
    "    #save_path a folder or directory where you want to save all processed images and files\n",
    "    #can switch the type of image being processed for stack_reg (asn't be tested on czi yet)\n",
    "    def __init__(self, image_directory, save_path, stack_reg=True, image_type='tif'):\n",
    "        self.image_directory = image_directory\n",
    "        self.save_path = save_path\n",
    "        self.stack_reg = stack_reg\n",
    "        self.image_type=image_type\n",
    "        \n",
    "    #takes the save_path and creates four new folders that will be used to save csv, overlays, and xmls to\n",
    "    #if self.stack_reg=True, create a directory to save the images post-processing\n",
    "    #Returns the path of directories to save the experiments data to\n",
    "    def save_directories(self):\n",
    "        dir_list = []\n",
    "        save_list = ['csv_files/', 'overlay_files/', 'xml_files/']\n",
    "        if self.stack_reg == True: \n",
    "            save_list.append('stack_dir/')\n",
    "        for direct in save_list:\n",
    "            save_dir = os.path.join(self.save_path, direct)\n",
    "            doesExist = os.path.exists(save_dir)\n",
    "            dir_list.append(save_dir)\n",
    "            if doesExist == False:\n",
    "                os.mkdir(save_dir)\n",
    "        return dir_list\n",
    "    \n",
    "    #Returns a list of all image files inside the directory\n",
    "    def get_image_list(self):\n",
    "        path_to_images = []\n",
    "        for directory, dir_names, file_names in os.walk(self.image_directory):\n",
    "            for file_name in file_names:\n",
    "                if file_name.split('.')[-1] == self.image_type:\n",
    "                    full_path = os.path.normpath(os.path.join(directory, file_name))\n",
    "                    path_to_images.append(full_path)\n",
    "            res = [i for n, i in enumerate(path_to_images) if i not in path_to_images[:n]]\n",
    "            path_to_images = res\n",
    "            return path_to_images\t\n",
    "    \n",
    "    #Operates if the self.stack_reg=True\n",
    "    #utilizes the legacy version of stack reg\n",
    "    #Works on a multidimension 4d image: can be used on a 3d, but a try or if implementation  \n",
    "    #needs to be added if there isless than 1 frame. \n",
    "    #Saves this to the stack_reg directory created before \n",
    "    def stack_reg_images(self):\n",
    "        if self.stack_reg == True:\n",
    "            save_location = self.save_directories()[3]\n",
    "            path_to_images = self.get_image_list()\n",
    "            img_list = []\n",
    "            for i in range(len(path_to_images)):\n",
    "                imp  = ij.IJ.openImage(path_to_images[i])\n",
    "                imp.show()\n",
    "                other_title = str(imp.getTitle())\n",
    "                img_title = path_to_images[i].split('\\\\')[-1].split('.')[0]\n",
    "                print(img_title)\n",
    "                img_dim = imp.getDimensions()[4]\n",
    "                for frame in range(img_dim):\n",
    "                    frame=frame+1\n",
    "                    w.getImage(other_title)\n",
    "                    if frame == 1:\n",
    "                        IJ.run(\"Duplicate...\", \"title=Stack_reg_image duplicate frames=\"+str(frame))\n",
    "                        IJ.run(\"StackReg \", \"transformation=[Rigid Body]\")\n",
    "                    elif frame > 1:\n",
    "                        IJ.selectWindow(other_title)\n",
    "                        IJ.run(\"Duplicate...\", \"title=channels duplicate frames=\"+str(frame))\n",
    "                        IJ.run(\"StackReg \", \"transformation=[Rigid Body]\")\n",
    "                        IJ.run(\"Concatenate...\", \"title=Stack_reg_image open image1=Stack_reg_image image2=channels image3=[-- None --]\")\n",
    "                img_stackreg =  w.getImage(\"Stack_reg_image\")\n",
    "                img_sr_title = str(img_stackreg.getTitle())\n",
    "                stack_reg_image_file = save_location+img_title+\"_StackRegImage.tif\"\n",
    "                IJ.save(img_stackreg, stack_reg_image_file)\n",
    "                img_list.append(stack_reg_image_file)\n",
    "                img_stackreg.close()\n",
    "                imp.close()\n",
    "        return img_list\n",
    "    \n",
    "    \n",
    "    #Cellpose-Trackmate processor takes the images from stack_reg_dir if self.stack_reg =True or from\n",
    "    #self.image_directory if stack_reg = False\n",
    "    #imaging dates can be either a string or list of strings\n",
    "    #if construct_in_file is False, the cell column will have a none data type\n",
    "    #if construct_in_file is set to true, set the position the construct is located in (assuming the split is '_')\n",
    "    #crossexcitation and blled through values for the scope or set up can be set\n",
    "    #cellpose_exe is dependent on the set up env, you should have a python.exe in the cellpose env\n",
    "    #model_location also depend on setup and which model you choose. \n",
    "    #model has to be set to Pretrained.Model, where Model can be CYTO, CYTO2, NUCLEI, or CUSTOM\n",
    "    #if set to custom ensure the cellpose_model_location is defined appropiately\n",
    "    #return value is a Pandas Dataframe of all the images and constructs in the directory\n",
    "    #save a capture of the overlay, csv files, and xml file of the tracks\n",
    "    def cellpose_processing(self, \n",
    "                            imaging_dates,\n",
    "                            construct_in_file=False,\n",
    "                            construct=None,\n",
    "                            experiment_in_file = False,\n",
    "                            experiment =None,\n",
    "                            well_in_file=False,\n",
    "                            well=None,\n",
    "                            position_in_file=False,\n",
    "                            position=None,\n",
    "                            cx=0.19,\n",
    "                            bt=0.53,\n",
    "                            cellpose_exe='C:/Users/Shahar_group_scope/anaconda3/envs/cellpose/python.exe', \n",
    "                            cellpose_model=PretrainedModel.CYTO, \n",
    "                            cellpose_model_location='C:/Users/Shahar_group_scope/Documents/Patrick/Stable_cells/24hr_troubleshooting/20230414_GS32/model_creation/models/CP_20230420_074409'):\n",
    "        \n",
    "        if self.stack_reg == True:\n",
    "            path_to_images = self.stack_reg_images()\n",
    "        else:\n",
    "            path_to_images = self.get_image_list()\n",
    "        csv_save=            self.save_directories()[0]\n",
    "        overlay_save=        self.save_directories()[1]\n",
    "        xml_save=            self.save_directories()[2]\n",
    "        full_df = pd.DataFrame()\n",
    "        for i in range(len(path_to_images)):\n",
    "            imp  = ij.IJ.openImage(path_to_images[i])\n",
    "            img_title = str(imp.getTitle())\n",
    "            \n",
    "            if isinstance(imaging_dates, list):\n",
    "                imaging_date = imaging_dates[i]\n",
    "            else:\n",
    "                imaging_date = imaging_dates\n",
    "            if construct_in_file == True: \n",
    "                cell = img_title.split(\"_\")[construct]\n",
    "            else:\n",
    "                cell= 0\n",
    "            if well_in_file == True: \n",
    "                well = img_title.split(\"_\")[well]\n",
    "            else:\n",
    "                well = 1\n",
    "            if well_in_file == True: \n",
    "                posi = img_title.split(\"_\")[position]\n",
    "            else:\n",
    "                posi = 1 \n",
    "                \n",
    "            process_date = date.today()\n",
    "            \n",
    "            csv_path = os.path.join(csv_save, img_title.split('.')[0])\n",
    "            overlay_path = os.path.join(overlay_save, img_title.split('.')[0])\n",
    "            xml_path = xml_save\n",
    "        \n",
    "            model = Model()\n",
    "            logger = LogRecorder( Logger.VOID_LOGGER )\n",
    "        \n",
    "            model.setLogger(Logger.IJ_LOGGER)\n",
    "\n",
    "            settings = Settings(imp)\n",
    "            \n",
    "            settings.detectorFactory = CellposeDetectorFactory()\n",
    "            settings.detectorSettings = {\n",
    "                'TARGET_CHANNEL' : ij.py.to_java(1),\n",
    "                'OPTIONAL_CHANNEL_2' : ij.py.to_java(0),\n",
    "                'CELLPOSE_PYTHON_FILEPATH' : cellpose_exe,\n",
    "                'CELLPOSE_MODEL' : cellpose_model,\t    \n",
    "                'CELLPOSE_MODEL_FILEPATH' : cellpose_model_location,\n",
    "                'CELL_DIAMETER' : 0.0,\n",
    "                'USE_GPU' : True,\n",
    "                'SIMPLIFY_CONTOURS' : False,\n",
    "            }\n",
    "            \n",
    "           \n",
    "            #tracker configuration, Variables can be added or subtracted, numbers can be changed accordingly\n",
    "            settings.trackerFactory = SparseLAPTrackerFactory()\n",
    "            settings.trackerSettings = settings.trackerFactory.getDefaultSettings()\n",
    "            settings.trackerSettings[ 'LINKING_MAX_DISTANCE' ]= 25.0\n",
    "            settings.trackerSettings[ 'GAP_CLOSING_MAX_DISTANCE' ]= 25.0\n",
    "            settings.trackerSettings[ 'MAX_FRAME_GAP' ]= ij.py.to_java(3)\n",
    "           \n",
    "            settings.addAllAnalyzers()\n",
    "           \n",
    "           \n",
    "            settings.initialSpotFilterValue = 1.\n",
    "            \n",
    "            print(str(settings))\n",
    "           \n",
    "            trackmate = TrackMate(model, settings)\n",
    "            trackmate.computeSpotFeatures( True )\n",
    "            trackmate.computeTrackFeatures( True )\n",
    "            trackmate.getModel().setLogger( logger )\n",
    "            \n",
    "            ok = trackmate.checkInput()\n",
    "            if not ok:\n",
    "                sys.exit(str(trackmate.getErrorMessage()))\n",
    "            \n",
    "            ok = trackmate.process()\n",
    "            if not ok:\n",
    "                sys.exit(str(trackmate.getErrorMessage()))\n",
    "           \n",
    "            saveFile = TMUtils.proposeTrackMateSaveFile( settings, logger )\n",
    "            model.getLogger().log('Found ' + str(model.getTrackModel().nTracks(True)) + ' tracks.')            \n",
    "           \n",
    "            sm = SelectionModel( model )            \n",
    "           \n",
    "            ds = DisplaySettingsIO.readUserDefault()\n",
    "                        \n",
    "            displayer =  HyperStackDisplayer( model, sm, imp, ds ) \n",
    "            displayer.render()\n",
    "           \n",
    "            image = trackmate.getSettings().imp\n",
    "            capture = CaptureOverlayAction.capture(image, -1, imp.getNFrames(), logger)\n",
    "            capture.setTitle(img_title+\"_TracksOverlay\")\n",
    "            cap_title = capture.getTitle()\n",
    "            IJ.save(capture, overlay_path+'_TracksOverlay.avi')\n",
    "            #IJ.run(capture, \"Calibration Bar...\", \"location=[Upper Right] fill=White label=Black number=5 decimal=0 font=12 zoom=1 overlay\")\n",
    "            \n",
    "            outFile = File(xml_path, img_title.split('.')[0]+\"_exportTracks.xml\")   #this will write the tracks only XML\n",
    "            ExportTracksToXML.export(model, settings, outFile)\n",
    "            outFile = File(xml_path, img_title.split('.')[0]+\"_exportModel.xml\")  # this will write the full trackmate xml.\n",
    "            xmlwriter = TmXmlWriter(outFile) \n",
    "            xmlwriter.appendModel(model)\n",
    "            xmlwriter.appendSettings(settings)\n",
    "            xmlwriter.writeToFile()                                             \n",
    "              \n",
    "            fm = model.getFeatureModel()\n",
    "            image_df=pd.DataFrame()\n",
    "                      \n",
    "            for id in model.getTrackModel().trackIDs(True):               \n",
    "                track_df = pd.DataFrame()\n",
    "                track_id = ij.py.from_java(id)\n",
    "                track = model.getTrackModel().trackSpots(id)\n",
    "                for spot in track:\n",
    "                    sid = ij.py.from_java(spot.ID())        \n",
    "                    t=ij.py.from_java(spot.getFeature('FRAME'))\n",
    "                    q=ij.py.from_java(spot.getFeature('QUALITY'))\n",
    "                    r=ij.py.from_java(spot.getFeature('RADIUS'))\n",
    "                    a=ij.py.from_java(spot.getFeature('AREA'))\n",
    "                    p=ij.py.from_java(spot.getFeature('PERIMETER'))\n",
    "                    c=ij.py.from_java(spot.getFeature('CIRCULARITY'))\n",
    "                    s=ij.py.from_java(spot.getFeature('SOLIDITY'))\n",
    "                    mean_1=ij.py.from_java(spot.getFeature('MEAN_INTENSITY_CH1'))\n",
    "                    mean_2=ij.py.from_java(spot.getFeature('MEAN_INTENSITY_CH2'))\n",
    "                    mean_3=ij.py.from_java(spot.getFeature('MEAN_INTENSITY_CH3'))\n",
    "                    std_1=ij.py.from_java(spot.getFeature('STD_INTENSITY_CH1'))\n",
    "                    std_2=ij.py.from_java(spot.getFeature('STD_INTENSITY_CH2'))\n",
    "                    std_3=ij.py.from_java(spot.getFeature('STD_INTENSITY_CH3'))\n",
    "                    mean_2_corrected= mean_2-mean_1*bt-mean_3*cx\n",
    "                    Efret= mean_2_corrected/(mean_1+mean_2_corrected)\n",
    "                    df = pd.DataFrame({'date_processed':[process_date], \n",
    "                                       'date_imaged':[imaging_date],\n",
    "                                       'file_name': [img_title.split('.')[0]],\n",
    "                                       'model_used':[cellpose_model], \n",
    "                                       'model_location':[cellpose_model_location], \n",
    "                                       'construct':[cell],\n",
    "                                       'experiment': experiment,\n",
    "                                       'well': well,\n",
    "                                       'position': posi,\n",
    "                                       'track_id':[track_id], \n",
    "                                       'frame': [t], \n",
    "                                       'Spot_ID':[sid], \n",
    "                                       'quality':[q],\n",
    "                                       'radius':[r], \n",
    "                                       'area':[a], \n",
    "                                       'perimeter':[p], \n",
    "                                       'circularity': [c],\n",
    "                                       'solidity': [s], \n",
    "                                       'donor_mean':[mean_1],\n",
    "                                       'acceptor_mean': [mean_2], \n",
    "                                       'acceptor_mean_corrected': [mean_2_corrected], \n",
    "                                       'efret':[Efret], \n",
    "                                       'direct_acceptor_mean':[mean_3],\n",
    "                                       'donor_Std': std_1,\n",
    "                                       'acceptor_std_ch2': std_2, \n",
    "                                       'direct_acceptor_std': std_3,})\n",
    "                    \n",
    "                    track_df = pd.concat([track_df, df])\n",
    "                    \n",
    "                image_df = pd.concat([image_df, track_df])        \n",
    "            image_df.to_csv(csv_path+'.csv', index=False)   \n",
    "            imp.close()\n",
    "            full_df = pd.concat([full_df, image_df])\n",
    "        full_df.to_csv(csv_save+'combined_data.csv', index=False)\n",
    "        return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657efd47-4036-4cda-ac35-cdce115f609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models, io\n",
    "from cellpose.io import *\n",
    "from collections import defaultdict\n",
    "import geopandas\n",
    "import glob\n",
    "import imagej\n",
    "from jpype import JArray, JInt\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas\n",
    "from pandas import DataFrame\n",
    "from pathlib import Path\n",
    "import scyjava\n",
    "import seaborn\n",
    "import shutil\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81311042-516d-41e1-ab36-f62e3880eb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0/1.54f'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{TARGET_CHANNEL=1, INTENSITY_THRESHOLD=5.0, SIMPLIFY_CONTOURS=false}\n",
      "{TARGET_CHANNEL=1, INTENSITY_THRESHOLD=5.0, SIMPLIFY_CONTOURS=false}\n",
      "{INTENSITY_THRESHOLD=5.0, SIMPLIFY_CONTOURS=false}\n",
      "{TARGET_CHANNEL=1, INTENSITY_THRESHOLD=5.0, SIMPLIFY_CONTOURS=false}\n",
      "{TARGET_CHANNEL=(int)1, INTENSITY_THRESHOLD=5.0, SIMPLIFY_CONTOURS=false}\n",
      "{TARGET_CHANNEL=(int)1, INTENSITY_THRESHOLD=5.0, SIMPLIFY_CONTOURS=false}\n",
      "{TARGET_CHANNEL=1, INTENSITY_THRESHOLD=5.0, SIMPLIFY_CONTOURS=false}\n",
      "{TARGET_CHANNEL=1, INTENSITY_THRESHOLD=5.0, SIMPLIFY_CONTOURS=false}\n",
      "{TARGET_CHANNEL=1, INTENSITY_THRESHOLD=5.0, SIMPLIFY_CONTOURS=false}\n"
     ]
    }
   ],
   "source": [
    "scyjava.config.add_option('-Xmx60g')\n",
    "start_dir = os.getcwd()\n",
    "#ij = imagej.init('sc.fiji:fiji', mode='interactive')\n",
    "ij = imagej.init('/Users/volkenlab/Documents/Jacques_Data/Fiji.app/', mode='interactive')\n",
    "## Something about this init() function changes the current working directory.\n",
    "#ij.getApp().getInfo(True)\n",
    "ij.ui().showUI()\n",
    "os.chdir(start_dir)\n",
    "ij.getVersion() #This is to make sure ImageJ/Fiji opened properly. In case of error, it could display '2.9.0/inactive' instead of the full version n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65d912d7-f726-4e29-982c-41d744d96e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[java.lang.Enum.toString] Starting detection process using 20 threads.\n",
      "[java.lang.Enum.toString] Detection processes 20 frames simultaneously and allocates 1 thread per frame.\n",
      "[java.lang.Enum.toString] Detection...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Found 75126 spots.\n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Starting initial filtering process.\n",
      "[java.lang.Enum.toString] Computing spot features over 20 frames simultaneously and allocating 1 thread per frame.\n",
      "[java.lang.Enum.toString] Calculating 75126 spots features...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Computation done in 32 ms.\n",
      "[java.lang.Enum.toString] Starting spot filtering process.\n",
      "[java.lang.Enum.toString] Starting tracking process.\n",
      "[java.lang.Enum.toString] Frame to frame linking...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Creating the segment linking cost matrix...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Creating the main cost matrix...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Completing the cost matrix...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Solving the cost matrix...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Creating links...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Computing edge features:\n",
      "[java.lang.Enum.toString] Computation done in 0 ms.\n",
      "[java.lang.Enum.toString] Computing track features:\n",
      "[java.lang.Enum.toString] Computation done in 0 ms.\n",
      "[java.lang.Enum.toString] Starting track filtering process.\n",
      "[java.lang.Enum.toString] Starting detection process using 20 threads.\n",
      "[java.lang.Enum.toString] Detection processes 20 frames simultaneously and allocates 1 thread per frame.\n",
      "[java.lang.Enum.toString] Detection...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Found 106841 spots.\n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Starting initial filtering process.\n",
      "[java.lang.Enum.toString] Computing spot features over 20 frames simultaneously and allocating 1 thread per frame.\n",
      "[java.lang.Enum.toString] Calculating 106841 spots features...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Computation done in 17 ms.\n",
      "[java.lang.Enum.toString] Starting spot filtering process.\n",
      "[java.lang.Enum.toString] Starting tracking process.\n",
      "[java.lang.Enum.toString] Frame to frame linking...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Creating the segment linking cost matrix...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Creating the main cost matrix...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Completing the cost matrix...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Solving the cost matrix...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Creating links...[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] \n",
      "[java.lang.Enum.toString] Computing edge features:\n",
      "[java.lang.Enum.toString] Computation done in 0 ms.\n",
      "[java.lang.Enum.toString] Computing track features:\n",
      "[java.lang.Enum.toString] Computation done in 0 ms.\n",
      "[java.lang.Enum.toString] Starting track filtering process.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "Model =  scyjava.jimport('fiji.plugin.trackmate.Model')\n",
    "Settings= scyjava.jimport('fiji.plugin.trackmate.Settings')\n",
    "TrackMate = scyjava.jimport('fiji.plugin.trackmate.TrackMate')\n",
    "Logger= scyjava.jimport('fiji.plugin.trackmate.Logger')\n",
    "DetectorKeys= scyjava.jimport('fiji.plugin.trackmate.detection.DetectorKeys') \n",
    "ExportTracksToXML= scyjava.jimport('fiji.plugin.trackmate.action.ExportTracksToXML') \n",
    "TmXmlWriter= scyjava.jimport('fiji.plugin.trackmate.io.TmXmlWriter')\n",
    "LogRecorder = scyjava.jimport('fiji.plugin.trackmate.util.LogRecorder')\n",
    "SparseLAPTrackerFactory= scyjava.jimport('fiji.plugin.trackmate.tracking.jaqaman.SparseLAPTrackerFactory')\n",
    "TMUtils = scyjava.jimport('fiji.plugin.trackmate.util.TMUtils')\n",
    "HyperStackDisplayer = scyjava.jimport('fiji.plugin.trackmate.visualization.hyperstack.HyperStackDisplayer')\n",
    "SelectionModel = scyjava.jimport('fiji.plugin.trackmate.SelectionModel')\n",
    "CellposeDetectorFactory = scyjava.jimport('fiji.plugin.trackmate.cellpose.CellposeDetectorFactory')\n",
    "FeatureFilter = scyjava.jimport('fiji.plugin.trackmate.features.FeatureFilter')\n",
    "DisplaySetting = scyjava.jimport('fiji.plugin.trackmate.gui.displaysettings.DisplaySettings')\n",
    "DisplaySettingsIO = scyjava.jimport('fiji.plugin.trackmate.gui.displaysettings.DisplaySettingsIO')\n",
    "CaptureOverlayAction = scyjava.jimport('fiji.plugin.trackmate.action.CaptureOverlayAction')\n",
    "PretrainedModel= scyjava.jimport('fiji.plugin.trackmate.cellpose.CellposeSettings.PretrainedModel')\n",
    "ThresholdDetectorFactory= scyjava.jimport('fiji.plugin.trackmate.detection.ThresholdDetectorFactory')\n",
    "TrackScheme = scyjava.jimport('fiji.plugin.trackmate.visualization.trackscheme.TrackScheme')\n",
    "TrackTableView = scyjava.jimport('fiji.plugin.trackmate.visualization.table.TrackTableView')\n",
    "AllSpotsTableView = scyjava.jimport('fiji.plugin.trackmate.visualization.table.AllSpotsTableView')\n",
    "\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "# Directory\n",
    "# Here, the user can specify the directory where the cell images are located\n",
    "src = \"/Users/volkenlab/Documents/Anushka/Images/\"\n",
    "out = src+\"Output/\"\n",
    "if not os.path.exists(out):\n",
    "    os.makedirs(out)\n",
    "\n",
    "# Parameters for Detection\n",
    "# Here, the user can specify parameters for the detection step in Trackmate (Threshold Detector)\n",
    "dsettings = {\n",
    "    'TARGET_CHANNEL' : ij.py.to_java(1),\n",
    "    'SIMPLIFY_CONTOURS' : False,\n",
    "    'INTENSITY_THRESHOLD' : 5.0,\n",
    "}\n",
    "\n",
    "# Parameters for Tracking\n",
    "# Here, the user can specify parameters for the tracking step in Trackmate (LAP Tracker)\n",
    "frame_gap = 2\n",
    "tsettings = {\n",
    "    'LINKING_MAX_DISTANCE' : 15.0,\n",
    "    'ALLOW_GAP_CLOSING' : True,\n",
    "    'GAP_CLOSING_MAX_DISTANCE' : 15.0,\n",
    "    'MAX_FRAME_GAP' : ij.py.to_java(2),\n",
    "    'ALLOW_TRACK_SPLITTING' : False,\n",
    "    'SPLITTING_MAX_DISTANCE' : 15.0,\n",
    "    'ALLOW_TRACK_MERGING' : False,\n",
    "}\n",
    "\n",
    "for image in os.listdir(src):\n",
    "    if (image[len(image)-4:] == \".tif\"):\n",
    "\n",
    "        # Open Image\n",
    "        imp = ij.IJ.openImage(src + image)\n",
    "        imp.show()\n",
    "        \n",
    "        # Create Model\n",
    "        model = Model()\n",
    "        settings = Settings(imp)\n",
    "        \n",
    "        # Detector\n",
    "        settings.detectorFactory = ThresholdDetectorFactory()\n",
    "        for parameter, value in dsettings.items():\n",
    "            #settings.detectorSettings.update({parameter:value})\n",
    "            settings.detectorSettings[parameter] = value\n",
    "        filter1 = FeatureFilter('QUALITY', 198, True)\n",
    "        settings.addSpotFilter(filter1)\n",
    "        print(settings.detectorSettings)\n",
    "        \n",
    "        # Tracker\n",
    "        settings.trackerFactory = SparseLAPTrackerFactory()\n",
    "        settings.trackerSettings = settings.trackerFactory.getDefaultSettings()\n",
    "        for parameter, value in tsettings.items():\n",
    "            #settings.trackerSettings.update({parameter:value})\n",
    "            settings.trackerSettings[parameter] = value\n",
    "        \n",
    "        # Execute Tracking\n",
    "        trackmate = TrackMate(model, settings)\n",
    "        ok = trackmate.checkInput()\n",
    "        if not ok:\n",
    "            sys.exit(str(trackmate.getErrorMessage()))\n",
    "        ok = trackmate.process()\n",
    "        if not ok:\n",
    "            sys.exit(str(trackmate.getErrorMessage()))\n",
    "        selectionModel = SelectionModel(model)\n",
    "        \n",
    "        # Display\n",
    "        ds = DisplaySettingsIO.readUserDefault()\n",
    "        displayer = HyperStackDisplayer(model, selectionModel, imp, ds)\n",
    "        displayer.render()\n",
    "        displayer.refresh()\n",
    "        trackscheme = TrackScheme(model, selectionModel, ds)\n",
    "        trackscheme.render()\n",
    "        \n",
    "        # Save Data\n",
    "        outFile = Path(out+image+\"_exportModel.xml\")\n",
    "        writer = TmXmlWriter(outFile)\n",
    "        writer.appendModel(model)\n",
    "        writer.appendSettings(settings)\n",
    "        writer.writeToFile()\n",
    "        csvFileTracks = Path(out+image+\"_exportTracks.csv\")\n",
    "        trackTableView = TrackTableView(model, selectionModel, ds)\n",
    "        trackTableView.getSpotTable().exportToCsv(csvFileTracks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
